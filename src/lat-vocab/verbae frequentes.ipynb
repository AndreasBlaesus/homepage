{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from cltk.stem.lemma import LemmaReplacer\n",
    "from cltk.stem.latin.j_v import JVReplacer\n",
    "from cltk.prosody.latin.macronizer import Macronizer\n",
    "import cltk.corpus.latin\n",
    "\n",
    "lemmatizer = LemmaReplacer('latin')\n",
    "macronizer = Macronizer('tag_ngram_123_backoff')\n",
    "jv_replacer = JVReplacer()\n",
    "\n",
    "nonword_name_abbreviations = 'Ap,A,D,F,C,Cn,H,L,Mai,Mam,M,Min,N,Oct,P,Q,Seq,Ser,Sp,St,T,Ti,V,Vol,Vop'.lower().split(',')\n",
    "\n",
    "def clean_entry(entry):\n",
    "    if (entry in nonword_name_abbreviations):\n",
    "        return entry.capitalize()+'.'\n",
    "    return ''.join(filter(lambda x: x.isalpha(), entry))\n",
    "\n",
    "def get_corpus_files(author):\n",
    "    fileids = filter(lambda s: s.startswith(author), cltk.corpus.latin.latinlibrary.fileids())\n",
    "    files = [cltk.corpus.latin.latinlibrary.abspath(fileid) for fileid in fileids]\n",
    "    return files\n",
    "\n",
    "def merge_file_contents(paths):\n",
    "    text = ''\n",
    "    for path in files:\n",
    "        f = open(path)\n",
    "        text += f.read()\n",
    "        #print('loaded', path, 'buffer length', len(text))\n",
    "        f.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = (\n",
    "    'caesar',\n",
    "    'livy',\n",
    "    'ovid',\n",
    "    'cicero',\n",
    "    'galileo',\n",
    "    'bacon',\n",
    "    'more',\n",
    ")\n",
    "\n",
    "data = {}\n",
    "for author in authors:\n",
    "    freq_table = []\n",
    "\n",
    "    files = get_corpus_files(author)\n",
    "    text = merge_file_contents(files)\n",
    "    text = clean_text(text)\n",
    "\n",
    "    tokens = lemmatizer.lemmatize(jv_replacer.replace(text).lower())\n",
    "    N = len(tokens)\n",
    "    longest_token = max(tokens, key=len)\n",
    "    freq_count = Counter(tokens)\n",
    "    data[author] = freq_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 qui             3.461% ( 3.5%) \n",
      "  100 locus           0.126% (45.1%) \n",
      "  200 annus           0.073% (54.5%) \n",
      "  300 summum          0.047% (60.3%) \n",
      "  400 romanis         0.037% (64.5%) \n",
      "  500 opinio          0.030% (67.7%) \n",
      "  600 intersum        0.025% (70.5%) \n",
      "  700 traho           0.021% (72.7%) \n",
      "  800 ignosco         0.018% (74.6%) \n",
      "  900 pulcher         0.015% (76.3%) \n",
      " 1000 caelo           0.014% (77.7%) \n",
      " 1100 descendo        0.012% (79.0%) \n",
      " 1200 spatior         0.011% (80.2%) \n",
      " 1300 labor           0.010% (81.2%) \n",
      " 1400 innocens        0.009% (82.1%) \n",
      " 1500 cora            0.008% (83.0%) \n",
      " 1600 municipium      0.007% (83.8%) \n",
      " 1700 opportunus      0.007% (84.5%) \n",
      " 1800 vicis           0.006% (85.2%) \n",
      " 1900 sollicitus      0.006% (85.8%) \n",
      " 2000 circumdo        0.006% (86.4%) \n",
      " 2100 radix           0.005% (86.9%) \n",
      " 2200 delectatio      0.005% (87.4%) \n",
      " 2300 uoluisse        0.004% (87.8%) \n",
      " 2400 matrona         0.004% (88.3%) \n",
      " 2500 subjecto        0.004% (88.7%) \n",
      " 2600 funditus        0.004% (89.1%) \n",
      " 2700 lapido          0.003% (89.4%) \n",
      " 2800 pomum           0.003% (89.7%) \n",
      " 2900 animaduertit    0.003% (90.0%) \n",
      " 3000 patrimonium     0.003% (90.3%) \n",
      " 3100 hirtus          0.003% (90.6%) \n",
      " 3200 procumbo        0.003% (90.9%) \n",
      " 3300 sagitta         0.002% (91.1%) \n",
      " 3400 intelligo       0.002% (91.4%) \n",
      " 3500 procreo         0.002% (91.6%) \n",
      " 3600 exordior        0.002% (91.8%) \n",
      " 3700 africanum       0.002% (92.0%) \n",
      " 3800 suburbanus      0.002% (92.2%) \n",
      " 3900 ubertas         0.002% (92.4%) \n",
      " 4000 apuliam         0.002% (92.5%) \n",
      " 4100 subsisto        0.002% (92.7%) \n",
      " 4200 progenies       0.002% (92.9%) \n",
      " 4300 simpliciter     0.002% (93.0%) \n",
      " 4400 ulixes          0.001% (93.2%) \n",
      " 4500 irritus         0.001% (93.3%) \n",
      " 4600 sciscitor       0.001% (93.4%) \n",
      " 4700 subscribo       0.001% (93.6%) \n",
      " 4800 illyriorum      0.001% (93.7%) \n",
      " 4900 locros          0.001% (93.8%) \n",
      " 5000 obstipesco      0.001% (93.9%) \n"
     ]
    }
   ],
   "source": [
    "def normalize(freq_table):\n",
    "    result = freq_table.copy()\n",
    "    N = sum(freq_table.values())\n",
    "    for lemma in result:\n",
    "        result[lemma] /= N\n",
    "    return result\n",
    "\n",
    "def normalize_all(data):\n",
    "    result = data.copy()\n",
    "    for author in result:\n",
    "        result[author] = normalize(result[author])\n",
    "    return result\n",
    "\n",
    "def merge_all(data):\n",
    "    result = Counter()\n",
    "    for author in data:\n",
    "        result += data[author]\n",
    "    return result\n",
    "\n",
    "def percent(n, decimal=2):\n",
    "    return '{:.{decimal}f}'.format(n * 100, decimal=decimal) + '%'\n",
    "\n",
    "def word_use_detail(word, author):\n",
    "    author_data = data[author]\n",
    "    N = sum(author_data.values())\n",
    "    return author + ':' + str(percent(author_data[word] / N, 2))\n",
    "\n",
    "    \n",
    "\n",
    "PERIOD = 100\n",
    "LAST_WORD = 5000\n",
    "SHOW_DETAILS = False\n",
    "\n",
    "def print_counter_data(counter):\n",
    "    coverage = 0\n",
    "    N = sum(counter.values())\n",
    "    index = 1\n",
    "    for word, freq in counter.most_common(LAST_WORD):\n",
    "        coverage += freq / N\n",
    "        if index == 1 or index % PERIOD == 0:\n",
    "\n",
    "            details = ' '.join([word_use_detail(word, author) for author in authors])\n",
    "            print(\n",
    "                '%5s' % index,\n",
    "                '%-15s' % clean_entry(word),\n",
    "                '%6s' % percent(freq, 3),\n",
    "                '(%5s)' % percent(coverage, 1),\n",
    "                details if SHOW_DETAILS else '',\n",
    "            )\n",
    "        index += 1\n",
    "\n",
    "normalized_combined_freq_table = normalize(merge_all(data))\n",
    "print_counter_data(normalized_combined_freq_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
