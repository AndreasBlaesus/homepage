{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from cltk.stem.lemma import LemmaReplacer\n",
    "from cltk.stem.latin.j_v import JVReplacer\n",
    "from cltk.prosody.latin.macronizer import Macronizer\n",
    "import cltk.corpus.latin\n",
    "\n",
    "lemmatizer = LemmaReplacer('latin')\n",
    "macronizer = Macronizer('tag_ngram_123_backoff')\n",
    "jv_replacer = JVReplacer()\n",
    "\n",
    "skip_chars = '0123456789`~!@#$%^&*()))_+-={}[]|\\:;\"\\'<>?,./'\n",
    "\n",
    "def clean_text(text):\n",
    "    table = {ord(char): None for char in skip_chars}\n",
    "    return text.translate(table)\n",
    "\n",
    "nonword_name_abbreviations = 'Ap,A,D,F,C,Cn,H,L,Mai,Mam,M,Min,N,Oct,P,Q,Seq,Ser,Sp,St,T,Ti,V,Vol,Vop'.lower().split(',')\n",
    "\n",
    "def clean_entry(entry):\n",
    "    if (entry in nonword_name_abbreviations):\n",
    "        return entry.capitalize()+'.'\n",
    "    return ''.join(filter(lambda x: x.isalpha(), entry))\n",
    "\n",
    "def get_corpus_files(author):\n",
    "    fileids = filter(lambda s: s.startswith(author), cltk.corpus.latin.latinlibrary.fileids())\n",
    "    files = [cltk.corpus.latin.latinlibrary.abspath(fileid) for fileid in fileids]\n",
    "    return files\n",
    "\n",
    "def merge_file_contents(paths):\n",
    "    text = ''\n",
    "    for path in files:\n",
    "        f = open(path)\n",
    "        text += f.read()\n",
    "        #print('loaded', path, 'buffer length', len(text))\n",
    "        f.close()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = (\n",
    "    'caesar',\n",
    "    'livy',\n",
    "    'ovid',\n",
    "    'cicero',\n",
    "    'galileo',\n",
    "    'bacon',\n",
    "    'more',\n",
    ")\n",
    "\n",
    "data = {}\n",
    "for author in authors:\n",
    "    freq_table = []\n",
    "\n",
    "    files = get_corpus_files(author)\n",
    "    text = merge_file_contents(files)\n",
    "    text = clean_text(text)\n",
    "\n",
    "    tokens = lemmatizer.lemmatize(jv_replacer.replace(text).lower())\n",
    "    N = len(tokens)\n",
    "    longest_token = max(tokens, key=len)\n",
    "    freq_count = Counter(tokens)\n",
    "    data[author] = freq_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(freq_table):\n",
    "    result = freq_table.copy()\n",
    "    N = sum(freq_table.values())\n",
    "    for lemma in result:\n",
    "        result[lemma] /= N\n",
    "    return result\n",
    "\n",
    "def normalize_all(data):\n",
    "    result = data.copy()\n",
    "    for author in result:\n",
    "        result[author] = normalize(result[author])\n",
    "    return result\n",
    "\n",
    "def merge_all(data):\n",
    "    result = Counter()\n",
    "    for author in data:\n",
    "        result += data[author]\n",
    "    return result\n",
    "\n",
    "def percent(n, decimal=2):\n",
    "    return '{:.{decimal}f}'.format(n * 100, decimal=decimal) + '%'\n",
    "\n",
    "def word_use_detail(word, author):\n",
    "    author_data = data[author]\n",
    "    N = sum(author_data.values())\n",
    "    return author[0:3] + ':' + str(percent(author_data[word] / N, 2))\n",
    "\n",
    "PERIOD = 1\n",
    "LAST_WORD = 2000\n",
    "SHOW_DETAILS = True\n",
    "\n",
    "def print_counter_data(counter):\n",
    "    coverage = 0\n",
    "    N = sum(counter.values())\n",
    "    index = 1\n",
    "    for word, freq in counter.most_common(LAST_WORD):\n",
    "        coverage += freq / N\n",
    "        if index == 1 or index % PERIOD == 0:\n",
    "\n",
    "            details = ' '.join([word_use_detail(word, author) for author in authors])\n",
    "            print(\n",
    "                '%5s' % index,\n",
    "                '%-15s' % clean_entry(word),\n",
    "                '%6s' % percent(freq, 3),\n",
    "                '(%5s)' % percent(coverage, 1),\n",
    "                details if SHOW_DETAILS else '',\n",
    "            )\n",
    "        index += 1\n",
    "\n",
    "normalized_combined_freq_table = normalize(merge_all(data))\n",
    "print_counter_data(normalized_combined_freq_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
